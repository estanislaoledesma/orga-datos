{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try:\n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = [\"a\", \"about\", \"above\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\",\\\n",
    "                \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\",\\\n",
    "              \"below\", \"tween\", \"bot\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\",\\\n",
    "              \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\\\n",
    "              \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\",\\\n",
    "              \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\\\n",
    "              \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"u'if\", \"in\", \"into\", \"is\",\\\n",
    "              \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\",\\\n",
    "              \"my\", \"myself\", \"of\", \"off\", \"on\", \"once\",\\\n",
    "              \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\\\n",
    "              \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\",\\\n",
    "              \"should\", \"so\", \"some\", \"such\", \"than\", \"that\",\"that's\",\\\n",
    "              \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\\\n",
    "              \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\",\\\n",
    "              \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\",\\\n",
    "             \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\",\\\n",
    "              \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\",\\\n",
    "              \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\\\n",
    "              \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\",\\\n",
    "              \"yourself\", \"yourselves\"]\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "\n",
    "def quitar_reviews_repetidos(reviewsRDD):\n",
    "    reviews_sin_rep = reviewsRDD.map( lambda review: (review.Text, review) )\\\n",
    "                    .reduceByKey( lambda review1, review2: review1 )\n",
    "\n",
    "    reviews_sin_rep = reviews_sin_rep.map(lambda x: x[1])\n",
    "\n",
    "    return reviews_sin_rep\n",
    "\n",
    "def preprocesar(review):\n",
    "    texto = quitar_signos(review.Text)\n",
    "    resumen = quitar_signos(review.Summary)\n",
    "\n",
    "    #texto = texto.lower()\n",
    "    #resumen = resumen.lower()\n",
    "\n",
    "    texto_palabras = texto.split(\" \")\n",
    "    resumen_palabras = resumen.split(\" \")\n",
    "    \n",
    "    texto = quitar_stopWords(texto_palabras)\n",
    "    resumen = quitar_stopWords(resumen_palabras)\n",
    "\n",
    "    estructura = [review.Id, review.Prediction, resumen+texto]\n",
    "\n",
    "    return estructura\n",
    "\n",
    "\n",
    "def quitar_signos(texto):\n",
    "    text = \"\"\n",
    "    if texto is not None:\n",
    "        text = texto.replace(\"<br />\", \" \")\n",
    "        text = re.sub(\"[^a-zA-Z' ]\", ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def quitar_stopWords(texto):\n",
    "    text = []\n",
    "    for palabra in texto:\n",
    "        palabra = palabra.lower()\n",
    "        if palabra not in stop_words and palabra != '':\n",
    "            text.append(palabra)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279582\n",
      "5\n",
      "[u'love', u'healthy', u'delicious', u'tastes', u'great', u'spread', u'apple', u'banana', u'honey', u'adds', u'just', u'enough', u'sweetness', u'make', u'taste', u'like', u'guilty', u'pleasure', u'without', u'making', u'overly', u'sugary']\n"
     ]
    }
   ],
   "source": [
    "import pyspark_csv as pycsv\n",
    "\n",
    "trainRDD = sc.textFile('data_train.csv')\n",
    "train_dataframe = pycsv.csvToDataFrame(sqlCtx, trainRDD, parseDate=False)\n",
    "train = train_dataframe.rdd\n",
    "\n",
    "\n",
    "train_sin_rep = quitar_reviews_repetidos(train)\n",
    "\n",
    "train_preprocesado = train_sin_rep.map(preprocesar)\n",
    "\n",
    "for x in train_preprocesado.take(1):\n",
    "    for y in x:\n",
    "        print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201541\n",
      "3\n",
      "[u'not', u'entirely', u'satisfied', u'even', u'though', u'shipping', u'super', u'fast', u'not', u'good', u'hoped', u'pretty', u'sure', u'received', u'pound', u'half', u'definitely', u'not', u'full', u'two', u'pounds', u'guess', u'fine', u\"don't\", u'see', u'finishing', u'given', u'flavor', u'decent', u'but', u'no', u'near', u'good', u'dried', u'papaya', u'can', u\"didn't\", u'seem', u'fresh', u'either', u'probably', u'wont', u'reordering', u'item', u'again']\n"
     ]
    }
   ],
   "source": [
    "testRDD = sc.textFile('data_test.csv')\n",
    "test_dataframe = pycsv.csvToDataFrame(sqlCtx, testRDD, parseDate=False)\n",
    "test = test_dataframe.rdd\n",
    "\n",
    "\n",
    "test_sin_rep = quitar_reviews_repetidos(test)\n",
    "\n",
    "test_preprocesado = test_sin_rep.map(preprocesar)\n",
    "\n",
    "for x in test_preprocesado.take(1):\n",
    "#    print \"x: \", x\n",
    "    for y in x:\n",
    "        print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def armar_palabras_con_sentimiento(nombre_archivo):\n",
    "    palabras_con_sentimiento = []\n",
    "    with open(nombre_archivo, 'r') as arch:\n",
    "        for word in arch:\n",
    "            word = word.rstrip(\"\\n\")\n",
    "            palabras_con_sentimiento.append(word)\n",
    "\n",
    "    return set(palabras_con_sentimiento)\n",
    "\n",
    "\n",
    "def sentimiento(review):\n",
    "\n",
    "    sentimiento = 0\n",
    "    pos = []\n",
    "    neg = []\n",
    "\n",
    "\n",
    "    for i in range( len(review) ):\n",
    "        word_ant = \"\"\n",
    "        if i>0:\n",
    "            word_ant = review[i-1]\n",
    "        \n",
    "        word = review[i]\n",
    "        \n",
    "        if word in palabras_positivas:\n",
    "            if word_ant not in palabras_sentimiento_inverso:\n",
    "                sentimiento += 1\n",
    "                pos.append(word)\n",
    "            else:\n",
    "                sentimiento -= 1\n",
    "                neg.append(word)\n",
    "\n",
    "        if word in palabras_negativas:\n",
    "            if word_ant not in palabras_sentimiento_inverso:\n",
    "                sentimiento -= 1\n",
    "                neg.append(word)\n",
    "            else:\n",
    "                sentimiento += 1\n",
    "                pos.append(word)\n",
    "\n",
    "    return [float(sentimiento), pos, neg]\n",
    "#    return float(sentimiento)\n",
    "\n",
    "\n",
    "\n",
    "palabras_positivas = armar_palabras_con_sentimiento(\"positive-words\")\n",
    "palabras_negativas = armar_palabras_con_sentimiento(\"negative-words\")\n",
    "\n",
    "palabras_sentimiento_inverso = [\"not\", \"ain't\", \"bareley\", \"aren't\", \"can't\", \"couldn't\", \"didn't\", \"doesn't\",\\\n",
    "                                \"don't\", \"hadn't\", \"few\", \"hardly\", \"low\", \"merely\", \"neither\", \"never\",\\\n",
    "                                \"no\", \"nor\", \"nobody\", \"none\", \"nope\", \"nothing\", \"rarely\", \"seldom\",\\\n",
    "                                \"hasn't\", \"haven't\", \"isn't\", \"mustn't\", \"shan't\", \"shouldn't\", \"used\",\\\n",
    "                                \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", \"zero\"]\n",
    "\n",
    "\n",
    "palabras_sentimiento_inverso = set(palabras_sentimiento_inverso)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def armar_palabras_con_sentimiento2(nombre_archivo):\n",
    "    palabras_con_sentimiento = {}\n",
    "    with open(nombre_archivo, 'r') as arch:\n",
    "        for word in arch:\n",
    "#            print \"word1: \", word\n",
    "            word = word.rstrip(\"\\n\")\n",
    "#            word = word.rstrip(\"\\t\")\n",
    "#            print \"word2: \", word\n",
    "            word = word.split(\"\\t\")\n",
    "#            print \"word: \", word\n",
    "            palabras_con_sentimiento[word[0]] = int(word[1])\n",
    "\n",
    "    return palabras_con_sentimiento\n",
    "\n",
    "def sentimiento2(review):\n",
    "    sentimiento = 0\n",
    "    words = []\n",
    "    \n",
    "    for word in review:\n",
    "        if word in palabras_sentimiento:\n",
    "            sentimiento += palabras_sentimiento[word]\n",
    "            words.append(word)\n",
    "    \n",
    "    return [sentimiento, words]\n",
    "\n",
    "\n",
    "palabras_sentimiento = armar_palabras_con_sentimiento2(\"AFINN-96.txt\")\n",
    "\n",
    "#print \"dict: \", palabras_sentimiento[\"aboard\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ARMAR PALABRAS CON SENTIMIENTO CON PESOS\n",
    "\n",
    "def armar_palabras_con_sentimiento(nombre_archivo_entrada, nombre_archivo_salida, valor_default):\n",
    "#    palabras_con_sentimiento = []\n",
    "    with open(nombre_archivo_salida, 'w') as arch_salida:\n",
    "        with open(nombre_archivo_entrada, 'r') as arch_entrada:\n",
    "            for word in arch_entrada:\n",
    "                s = \"\"\n",
    "                word = word.rstrip(\"\\n\")\n",
    "                \n",
    "                if word in palabras_sentimiento:\n",
    "                    s = word + \" \" + str(palabras_sentimiento[word]) + \"\\n\"\n",
    "                else:\n",
    "                    s = word + \" \" + valor_default + \"\\n\"\n",
    "\n",
    "                arch_salida.write(s)\n",
    "#                palabras_con_sentimiento.append(word)\n",
    "\n",
    "    return\n",
    "\n",
    "palabras_positivas = armar_palabras_con_sentimiento(\"positive-words\", \"positive-words-pesos\", \"1\")\n",
    "palabras_negativas = armar_palabras_con_sentimiento(\"negative-words\", \"negative-words-pesos\", \"-1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def armar_palabras_con_sentimiento3(nombre_archivo):\n",
    "    palabras_con_sentimiento = {}\n",
    "    with open(nombre_archivo, 'r') as arch:\n",
    "        for word in arch:\n",
    "#            print \"word1: \", word\n",
    "            word = word.rstrip(\"\\n\")\n",
    "#            word = word.rstrip(\"\\t\")\n",
    "#            print \"word2: \", word\n",
    "            word = word.split(\" \")\n",
    "#            print \"word: \", word\n",
    "            palabras_con_sentimiento[word[0]] = int(word[1])\n",
    "\n",
    "    return palabras_con_sentimiento\n",
    "\n",
    "def sentimiento3(review):\n",
    "\n",
    "    sentimiento = 0\n",
    "    pos = []\n",
    "    neg = []\n",
    "\n",
    "\n",
    "    for i in range( len(review) ):\n",
    "        word_ant = \"\"\n",
    "        if i>0:\n",
    "            word_ant = review[i-1]\n",
    "        \n",
    "        word = review[i]\n",
    "        \n",
    "        if word in palabras_pos:\n",
    "            if word_ant not in palabras_sentimiento_inverso:\n",
    "                sentimiento += palabras_pos[word]\n",
    "                pos.append(word)\n",
    "            else:\n",
    "                sentimiento -= palabras_pos[word]\n",
    "                neg.append(word)\n",
    "\n",
    "        if word in palabras_neg:\n",
    "            if word_ant not in palabras_sentimiento_inverso:\n",
    "                sentimiento += palabras_neg[word]\n",
    "                neg.append(word)\n",
    "            else:\n",
    "                sentimiento -= palabras_neg[word]\n",
    "                pos.append(word)\n",
    "\n",
    "    return [float(sentimiento), pos, neg]\n",
    "#    return float(sentimiento)\n",
    "\n",
    "\n",
    "palabras_pos = armar_palabras_con_sentimiento3(\"positive-words-pesos\")\n",
    "palabras_neg = armar_palabras_con_sentimiento3(\"negative-words-pesos\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suma_sent:  1860030.0\n",
      "cant_sent:  229077\n",
      "promedio_sent:  8.11967155149\n",
      "desv_std:  7.7588113562\n"
     ]
    }
   ],
   "source": [
    "## PARA NORMALIZAR DATOS\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def obtener_sent(review, sentimiento):\n",
    "    texto = review[2]\n",
    "    sent = sentimiento(texto)\n",
    "#    print \"sent: \", sent[0]\n",
    "    return (1, sent[0])\n",
    "\n",
    "sentimientos = train_preprocesado.map(lambda review: obtener_sent(review, sentimiento3))\n",
    "\n",
    "suma_sent = sentimientos.reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "suma_sent = suma_sent.collect()\n",
    "suma_sent = suma_sent[0][1]\n",
    "\n",
    "cant_sent = train_preprocesado.count()\n",
    "\n",
    "promedio_sent = float(suma_sent)/cant_sent\n",
    "\n",
    "print \"suma_sent: \", suma_sent\n",
    "print \"cant_sent: \", cant_sent\n",
    "print \"promedio_sent: \", promedio_sent\n",
    "\n",
    "\n",
    "ssd = sentimientos.map(lambda x: (1, ( x[1] - promedio_sent )**2 ) ).reduceByKey(lambda x, y: x+y)\n",
    "ssd = ssd.collect()\n",
    "ssd = ssd[0][1]\n",
    "\n",
    "varianza = ssd / (cant_sent-1)\n",
    "desv_std = sqrt(varianza)\n",
    "\n",
    "print \"desv_std: \", desv_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_PRED:  [201541, 3]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [6911, 2]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [461853, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [563294, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [471402, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [139618, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [248946, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [163663, 1]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [140792, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [340744, 1]\n",
      "PRED:  1.66666666667\n",
      "TEST_PRED:  [278204, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [165496, 1]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [415793, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [268341, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [371580, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [538393, 4]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [415317, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [524561, 1]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [55501, 3]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [545857, 5]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [64276, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [549022, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [402962, 4]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [514329, 5]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [549413, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [419544, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [206761, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [108099, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [267342, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [321418, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [131474, 1]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [466699, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [134792, 4]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [65195, 4]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [15231, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [206091, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [32605, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [43035, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [323477, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [140464, 3]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [319518, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [460611, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [309176, 3]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [410665, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [25508, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [152198, 4]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [352990, 4]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [266721, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [107812, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [499355, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [253273, 3]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [190130, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [172911, 1]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [231001, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [435736, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [385226, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [323953, 5]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [319405, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [271436, 1]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [147683, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [218448, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [469711, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [33160, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [121607, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [166383, 2]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [191079, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [30045, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [208336, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [565008, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [124276, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [260917, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [503095, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [564067, 3]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [25160, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [173632, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [28611, 3]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [566718, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [56698, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [36389, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [554634, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [823, 5]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [190174, 4]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [229283, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [130479, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [248282, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [389109, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [71639, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [91215, 3]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [181065, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [234106, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [412489, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [419115, 4]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [489362, 1]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [370772, 3]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [518729, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [42903, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [181626, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [104145, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [66398, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [244952, 4]\n",
      "PRED:  1.0\n",
      "ERROR:  11.9582607431\n",
      "accuracy:  27.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_pred = test[5]\\n\\nprint \"test: \", test_pred\\nprint \" \"\\n\\nprint \"test-sent: \", sentimiento(test_pred[2])\\nprint \" \"\\n\\n\\nk_mas_cercanos = knn(test_pred, 10, sentimiento)\\nprint \"k_mas_cercanos: \", k_mas_cercanos\\n\\nprediccion = predecir(k_mas_cercanos)\\n\\nprint \" \"\\nprint \"PRED: \", prediccion\\n\\n\\nk_mas_cercanos = knn(test_pred, 10, sentimiento2)\\nprint \"k_mas_cercanos2: \", k_mas_cercanos\\n\\nprediccion = predecir(k_mas_cercanos)\\n\\nprint \" \"\\nprint \"PRED2: \", prediccion\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def distancia(texto1_estruct, texto2_estruct, sentimiento):\n",
    "    texto1 = texto1_estruct[2]\n",
    "    texto2 = texto2_estruct[2]\n",
    "\n",
    "    sent1 = sentimiento(texto1)\n",
    "    sent1 = sent1[0]\n",
    "\n",
    "    sent2 = sentimiento(texto2)\n",
    "    sent2 = sent2[0]\n",
    "\n",
    "    ## NORMALIZO\n",
    "#    sent1 = (sent1 - promedio_sent) / desv_std\n",
    "#    sent2 = (sent2 - promedio_sent) / desv_std\n",
    "\n",
    "    dist = sqrt( (sent1 - sent2)**2 )\n",
    "\n",
    "    beta = 2\n",
    "    if dist == 0:\n",
    "        peso = float(\"inf\")\n",
    "    else:\n",
    "        peso = float(1) / dist**beta\n",
    "\n",
    "#    return [texto2_estruct[0], texto2_estruct[1], dist]\n",
    "    return [texto2_estruct[0], texto2_estruct[1], peso]\n",
    "\n",
    "\n",
    "def knn(texto_estruct, k, sentimiento):\n",
    "\n",
    "    dist = train_preprocesado.map(lambda vecino: distancia(texto_estruct, vecino, sentimiento))\n",
    "#    k_mas_cercanos = dist.takeOrdered(k, key=lambda x: x[2])\n",
    "\n",
    "    ## PARA DIST2\n",
    "    k_mas_cercanos = dist.takeOrdered(k, key=lambda x: -x[2])\n",
    "\n",
    "    return k_mas_cercanos\n",
    "\n",
    "def predecir(k_mas_cercanos):\n",
    "    prediccion_total = 0\n",
    "    for cercano in k_mas_cercanos:\n",
    "        prediccion_total += cercano[1]\n",
    "\n",
    "    return float(prediccion_total) / len(k_mas_cercanos)\n",
    "\n",
    "cant_ej = 10\n",
    "test = test_preprocesado.take(cant_ej)\n",
    "#for t in test:\n",
    "#    print \"t: \", t\n",
    "\n",
    "## PREDECIR VARIOS\n",
    "error = 0\n",
    "correct = 0\n",
    "for test_pred in test:\n",
    "    print \"TEST_PRED: \", test_pred[0:2]\n",
    "    k_mas_cercanos = knn(test_pred, 3, sentimiento3)\n",
    "    prediccion = predecir(k_mas_cercanos)\n",
    "\n",
    "    print \"PRED: \", prediccion\n",
    "\n",
    "    if prediccion == test_pred[1]:\n",
    "        correct += 1\n",
    "    error += (prediccion - test_pred[1])**2\n",
    "\n",
    "error = sqrt(error)\n",
    "print \"ERROR: \", error\n",
    "\n",
    "print \"accuracy: \", ( float(correct)/cant_ej ) * 100\n",
    "\n",
    "## PREDECIR UNO\n",
    "\"\"\"\n",
    "test_pred = test[5]\n",
    "\n",
    "print \"test: \", test_pred\n",
    "print \" \"\n",
    "\n",
    "print \"test-sent: \", sentimiento(test_pred[2])\n",
    "print \" \"\n",
    "\n",
    "\n",
    "k_mas_cercanos = knn(test_pred, 10, sentimiento)\n",
    "print \"k_mas_cercanos: \", k_mas_cercanos\n",
    "\n",
    "prediccion = predecir(k_mas_cercanos)\n",
    "\n",
    "print \" \"\n",
    "print \"PRED: \", prediccion\n",
    "\n",
    "\n",
    "k_mas_cercanos = knn(test_pred, 10, sentimiento2)\n",
    "print \"k_mas_cercanos2: \", k_mas_cercanos\n",
    "\n",
    "prediccion = predecir(k_mas_cercanos)\n",
    "\n",
    "print \" \"\n",
    "print \"PRED2: \", prediccion\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:  5\n",
      "SENT:  set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 79.0, 81.0, 83.0, 84.0, 89.0, 90.0, 105.0, 106.0, 109.0, 119.0, 142.0, -2.0, -44.0, -34.0, -33.0, -30.0, -29.0, -23.0, -22.0, -21.0, -20.0, -19.0, -18.0, -17.0, -16.0, -15.0, -14.0, -13.0, -12.0, -11.0, -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -1.0])\n",
      "PRED:  1\n",
      "SENT:  set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 30.0, 31.0, 32.0, 35.0, 36.0, 37.0, 40.0, 41.0, 43.0, 45.0, -80.0, -79.0, 50.0, 54.0, -66.0, -11.0, 69.0, 76.0, -49.0, -42.0, -37.0, -36.0, -35.0, -33.0, -31.0, -30.0, -29.0, -28.0, -27.0, -26.0, -25.0, -24.0, -23.0, -22.0, -21.0, -20.0, -19.0, -18.0, -17.0, -16.0, -15.0, -14.0, -13.0, -12.0, -2.0, -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -1.0])\n",
      "PRED:  2\n",
      "SENT:  set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 40.0, 41.0, 42.0, 43.0, 44.0, 46.0, 48.0, 50.0, 53.0, 60.0, -11.0, -29.0, -27.0, -23.0, -22.0, -21.0, -18.0, -17.0, -16.0, -15.0, -14.0, -13.0, -12.0, -2.0, -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -1.0])\n",
      "PRED:  3\n",
      "SENT:  set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 47.0, 49.0, 50.0, 52.0, 54.0, 56.0, -11.0, 65.0, -57.0, 74.0, 81.0, -41.0, -28.0, -24.0, -23.0, -21.0, -19.0, -17.0, -16.0, -15.0, -14.0, -13.0, -12.0, -2.0, -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -1.0])\n",
      "PRED:  4\n",
      "SENT:  set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 69.0, 72.0, 104.0, 129.0, -2.0, -54.0, -33.0, -26.0, -24.0, -22.0, -20.0, -19.0, -18.0, -17.0, -15.0, -14.0, -13.0, -12.0, -11.0, -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -1.0])\n"
     ]
    }
   ],
   "source": [
    "## CALCULAR SENTIMIENTO PARA CADA PREDICCION\n",
    "\n",
    "def foo(review):\n",
    "    pred = review[1]\n",
    "    texto = review[2]\n",
    "    sent = sentimiento3(texto)\n",
    "    \n",
    "    if pred == 5 and sent[0] == 0:\n",
    "        print \"id: \", review[0]\n",
    "        print \"texto: \", texto\n",
    "    \n",
    "    return ( pred, [sent[0]] )\n",
    "\n",
    "pred_sent = train_preprocesado.map(foo).reduceByKey( lambda a, b: a + b )\n",
    "\n",
    "pred_sent = pred_sent.collect()\n",
    "\n",
    "for x in pred_sent:\n",
    "    print \"PRED: \", x[0]\n",
    "    print \"SENT: \", set(x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " review:  [[412489, 5, [u'excellent', u'quality', u'first', u'adopted', u'dog', u'vast', u'amount', u'research', u'find', u'truly', u'best', u'feed', u'chihuahua', u'mix', u'reading', u'mixed', u'reviews', u'whether', u'small', u'dogs', u'benefit', u'high', u'protein', u'diet', u'not', u'decided', u'just', u'try', u'little', u'trouble', u'digestion', u'transitioning', u'food', u'eating', u'royal', u'canin', u'prior', u'eating', u'seven', u'months', u'now', u'phenomenal', u'great', u'muscle', u'tone', u'energy', u'coat', u'silky', u'shinny', u'coarse', u'dull', u'yes', u'pricey', u'side', u'but', u'if', u'closely', u'watch', u'put', u'body', u'humans', u\"wouldn't\", u'want', u'best', u'friend', u'benefit', u'great', u'food']]]\n",
      " \n",
      "sentimiento:  [4.0, [u'excellent', u'best', u'benefit', u'phenomenal', u'great', u'best', u'benefit', u'great'], [u'trouble', u'coarse', u'dull', u'pricey']]\n",
      " \n",
      "sentimiento2:  [19, [u'excellent', u'best', u'benefit', u'trouble', u'great', u'yes', u'want', u'best', u'benefit', u'great']]\n",
      " \n",
      "sentimiento3:  [15.0, [u'excellent', u'best', u'benefit', u'phenomenal', u'great', u'best', u'benefit', u'great'], [u'trouble', u'coarse', u'dull', u'pricey']]\n"
     ]
    }
   ],
   "source": [
    "## CALCULAR SENTIMIENTO PARA UN REVIEW ESPECIFICO\n",
    "\n",
    "reviewRDD = sc.textFile(\"review\")\n",
    "review_dataframe = pycsv.csvToDataFrame(sqlCtx, reviewRDD, parseDate=False)\n",
    "review = review_dataframe.rdd\n",
    "\n",
    "#test_sin_rep = quitar_reviews_repetidos(test)\n",
    "\n",
    "review_preprocesado = review.map(preprocesar)\n",
    "\n",
    "review = review_preprocesado.collect()\n",
    "print \"review: \", review\n",
    "\n",
    "print \" \"\n",
    "print \"sentimiento: \", sentimiento(review[0][2])\n",
    "\n",
    "print \" \"\n",
    "print \"sentimiento2: \", sentimiento2(review[0][2])\n",
    "\n",
    "print \" \"\n",
    "print \"sentimiento3: \", sentimiento3(review[0][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "frecs_por_docs:  {u'neighbors': 1, u'just': 1, u\"don't\": 1, u'money': 1, u'go': 1, u'yes': 1, u'find': 1, u'chihuahua': 1, u'earned': 1, u'less': 1, u'royal': 1, u'wasting': 1, u'shinny': 1, u'holiday': 1, u'worth': 1, u'food': 1, u'watch': 1, u'truly': 1, u'amazon': 1, u'closely': 1, u'not': 2, u'trouble': 1, u'now': 1, u'vast': 1, u'like': 1, u'gift': 1, u'try': 1, u'benefit': 1, u'overflowing': 1, u'small': 1, u'tower': 1, u'side': 1, u'energy': 1, u'hard': 1, u'humans': 1, u'decided': 1, u'best': 1, u'silky': 1, u'phenomenal': 1, u'research': 1, u'reading': 1, u'body': 1, u'full': 1, u'eating': 1, u'put': 2, u'appears': 1, u'great': 1, u'goods': 1, u\"wouldn't\": 1, u'months': 1, u'times': 1, u'kosher': 1, u'prior': 1, u'amount': 1, u'mixed': 1, u'makes': 1, u'first': 2, u'feed': 1, u'fantastic': 1, u'digestion': 1, u'tone': 1, u'feel': 1, u'canin': 1, u'tiny': 1, u'array': 1, u'quality': 1, u'little': 1, u'negative': 1, u'long': 1, u'next': 1, u'wonderful': 1, u'coarse': 1, u'taken': 1, u'transitioning': 1, u'dogs': 1, u'friend': 1, u'adopted': 1, u'but': 2, u'pricey': 1, u'excellent': 1, u'fooled': 1, u'dull': 1, u'grocery': 1, u'look': 1, u'whether': 1, u'leave': 1, u'cash': 1, u'value': 1, u'reviews': 2, u'store': 1, u'seven': 1, u'want': 1, u'dog': 1, u'high': 1, u'something': 1, u'purchased': 1, u'protein': 1, u'if': 1, u'large': 1, u'reality': 1, u'mix': 1, u'inch': 1, u'picture': 1, u'dime': 1, u'diet': 1, u'nothing': 1, u'stack': 1, u'coat': 1, u'boxes': 1, u'together': 1, u'time': 1, u'basket': 1, u'tall': 1, u'muscle': 1, u'normally': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bow(review):\n",
    "    texto = review[2]\n",
    "    frec = {}\n",
    "    for word in texto:\n",
    "        if word in frec:\n",
    "            frec[word] += 1\n",
    "        else:\n",
    "            frec[word] = 1\n",
    "\n",
    "    review.append(frec)\n",
    "    return review\n",
    "#    return frec\n",
    "\n",
    "def frec_por_doc(review):\n",
    "    texto = set(review[2])\n",
    "    words = []\n",
    "    for word in texto:\n",
    "        words.append( (word, 1) )\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "review_frec = review_preprocesado.map(bow)\n",
    "#print \"frec:\", review_frec.collect()\n",
    "\n",
    "frecs_por_docs = review_preprocesado.flatMap(frec_por_doc).reduceByKey( lambda x,y: x+y )\n",
    "frecs_por_docs = frecs_por_docs.collect()\n",
    "\n",
    "frec = {}\n",
    "\n",
    "for word in frecs_por_docs:\n",
    "    frec[word[0]] = word[1]\n",
    "\n",
    "print \" \"\n",
    "print \"frecs_por_docs: \", frec\n",
    "\n",
    "\n",
    "cant_reviews = review_preprocesado.count()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
