{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try:\n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = [\"a\", \"about\", \"above\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\",\\\n",
    "                \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\",\\\n",
    "              \"below\", \"tween\", \"bot\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\",\\\n",
    "              \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\\\n",
    "              \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\",\\\n",
    "              \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\\\n",
    "              \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"u'if\", \"in\", \"into\", \"is\",\\\n",
    "              \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\",\\\n",
    "              \"my\", \"myself\", \"of\", \"off\", \"on\", \"once\",\\\n",
    "              \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\\\n",
    "              \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\",\\\n",
    "              \"should\", \"so\", \"some\", \"such\", \"than\", \"that\",\"that's\",\\\n",
    "              \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\\\n",
    "              \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\",\\\n",
    "              \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\",\\\n",
    "             \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\",\\\n",
    "              \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\",\\\n",
    "              \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\\\n",
    "              \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\",\\\n",
    "              \"yourself\", \"yourselves\"]\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "palabras_sentimiento_inverso = [\"not\", \"ain't\", \"bareley\", \"aren't\", \"can't\", \"couldn't\", \"didn't\", \"doesn't\",\\\n",
    "                                \"don't\", \"hadn't\", \"few\", \"hardly\", \"low\", \"merely\", \"neither\", \"never\",\\\n",
    "                                \"no\", \"nor\", \"nobody\", \"none\", \"nope\", \"nothing\", \"rarely\", \"seldom\",\\\n",
    "                                \"hasn't\", \"haven't\", \"isn't\", \"mustn't\", \"shan't\", \"shouldn't\", \"used\",\\\n",
    "                                \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", \"zero\"]\n",
    "\n",
    "\n",
    "palabras_sentimiento_inverso = set(palabras_sentimiento_inverso)\n",
    "\n",
    "\n",
    "\n",
    "def quitar_reviews_repetidos(reviewsRDD):\n",
    "    reviews_sin_rep = reviewsRDD.map( lambda review: (review.Text, review) )\\\n",
    "                    .reduceByKey( lambda review1, review2: review1 )\n",
    "\n",
    "    reviews_sin_rep = reviews_sin_rep.map(lambda x: x[1])\n",
    "\n",
    "    return reviews_sin_rep\n",
    "\n",
    "def preprocesar(review):\n",
    "    texto = quitar_signos(review.Text)\n",
    "    resumen = quitar_signos(review.Summary)\n",
    "\n",
    "#    texto = texto.lower()\n",
    "#    resumen = resumen.lower()\n",
    "\n",
    "    texto_palabras = texto.split(\" \")\n",
    "    resumen_palabras = resumen.split(\" \")\n",
    "\n",
    "#    texto_palabras = texto_palabras + ngrams(texto_palabras, 2)\n",
    "#    resumen_palabras = resumen_palabras + ngrams(resumen_palabras, 2)\n",
    "\n",
    "    texto_palabras = quitar_stopWords(texto_palabras)\n",
    "    resumen_palabras = quitar_stopWords(resumen_palabras)\n",
    "\n",
    "    estructura = [review.Id, review.Prediction, resumen_palabras+texto_palabras]\n",
    "\n",
    "    return estructura\n",
    "\n",
    "\n",
    "def quitar_signos(texto):\n",
    "    text = \"\"\n",
    "    if texto is not None:\n",
    "        text = texto.replace(\"<br />\", \" \")\n",
    "        text = re.sub(\"[^a-zA-Z' ]\", ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def quitar_stopWords(texto):\n",
    "    text = []\n",
    "\n",
    "    for i in range( len(texto) ):\n",
    "        palabra = texto[i].lower()\n",
    "        if palabra not in stop_words and palabra != '':\n",
    "\n",
    "            if palabra in palabras_sentimiento_inverso and i+1 < len(texto):\n",
    "                palabra = palabra + \" \" + texto[i+1].lower()\n",
    "                text.append(palabra)\n",
    "\n",
    "            if i > 0 and texto[i-1].lower() not in palabras_sentimiento_inverso:\n",
    "                text.append(palabra)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def ngrams(texto, n):\n",
    "    #texto = texto.split(\" \")\n",
    "    lista_ngrams = []\n",
    "    for i in xrange(0, len(texto)-n-1):\n",
    "        lista_ngrams.append(\" \".join(texto[i:i+n]))\n",
    "\n",
    "    return lista_ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279582\n",
      "5\n",
      "[u'healthy', u'delicious', u'tastes', u'great', u'spread', u'apple', u'banana', u'honey', u'adds', u'just', u'enough', u'sweetness', u'make', u'taste', u'like', u'guilty', u'pleasure', u'without', u'making', u'overly', u'sugary']\n"
     ]
    }
   ],
   "source": [
    "import pyspark_csv as pycsv\n",
    "\n",
    "trainRDD = sc.textFile('data_train.csv')\n",
    "train_dataframe = pycsv.csvToDataFrame(sqlCtx, trainRDD, parseDate=False)\n",
    "train = train_dataframe.rdd\n",
    "\n",
    "\n",
    "train_sin_rep = quitar_reviews_repetidos(train)\n",
    "\n",
    "train_preprocesado = train_sin_rep.map(preprocesar)\n",
    "\n",
    "for x in train_preprocesado.take(1):\n",
    "    for y in x:\n",
    "        print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201541\n",
      "3\n",
      "[u'not entirely', u'satisfied', u'though', u'shipping', u'super', u'fast', u'not as', u'not as', u'good', u'hoped', u'pretty', u'sure', u'received', u'pound', u'half', u'definitely', u'not the', u'not the', u'full', u'two', u'pounds', u'guess', u'fine', u\"don't see\", u\"don't see\", u'finishing', u'given', u'flavor', u'decent', u'but', u'no where', u'no where', u'near', u'good', u'dried', u'papaya', u'can', u\"didn't seem\", u\"didn't seem\", u'fresh', u'either', u'probably', u'wont', u'reordering', u'item', u'again']\n"
     ]
    }
   ],
   "source": [
    "testRDD = sc.textFile('data_test.csv')\n",
    "test_dataframe = pycsv.csvToDataFrame(sqlCtx, testRDD, parseDate=False)\n",
    "test = test_dataframe.rdd\n",
    "\n",
    "\n",
    "test_sin_rep = quitar_reviews_repetidos(test)\n",
    "\n",
    "test_preprocesado = test_sin_rep.map(preprocesar)\n",
    "\n",
    "for x in test_preprocesado.take(1):\n",
    "#    print \"x: \", x\n",
    "    for y in x:\n",
    "        print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SVM DeltaTFIDF\n",
    "\n",
    "def bow(review):\n",
    "    texto = review[2]\n",
    "    frec = {}\n",
    "    for word in texto:\n",
    "        if word in frec:\n",
    "            frec[word] += 1\n",
    "        else:\n",
    "            frec[word] = 1\n",
    "\n",
    "    review.append(frec)\n",
    "    return review\n",
    "#    return frec\n",
    "\n",
    "train_frec = train_preprocesado.map(bow)\n",
    "\n",
    "\n",
    "def frec_por_doc(review):\n",
    "    texto = set(review[2])\n",
    "    words = []\n",
    "    for word in texto:\n",
    "        words.append( (word, 1) )\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "positivas = train_preprocesado.filter( lambda review: review[1]==4 or review[1]==5)\n",
    "cant_pos = positivas.count()\n",
    "\n",
    "frec_por_doc_pos = positivas.flatMap(frec_por_doc).reduceByKey( lambda x,y: x+y )\n",
    "frec_por_doc_pos = frec_por_doc_pos.collect()\n",
    "\n",
    "frec_pos = {}\n",
    "\n",
    "for word in frec_por_doc_pos:\n",
    "    frec_pos[word[0]] = word[1]\n",
    "\n",
    "\n",
    "negativas = train_preprocesado.filter( lambda review: review[1]==1 or review[1]==2 or review[1]==3 )\n",
    "cant_neg = negativas.count()\n",
    "\n",
    "frec_por_doc_neg = negativas.flatMap(frec_por_doc).reduceByKey( lambda x,y: x+y )\n",
    "frec_por_doc_neg = frec_por_doc_neg.collect()\n",
    "\n",
    "frec_neg = {}\n",
    "\n",
    "for word in frec_por_doc_neg:\n",
    "    frec_neg[word[0]] = word[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def delta_tfidf_ant(review_test, review_train):\n",
    "    texto = review_test[2]\n",
    "    frec_word = review_train[3]\n",
    "    Vt = 0\n",
    "\n",
    "    ##TF-IDF\n",
    "    k = 2\n",
    "    b = 0.75\n",
    "    long_doc = len(texto)\n",
    "    norm = 1 - b + b * (long_doc / promedio_long_docs)\n",
    "\n",
    "    for word in texto:\n",
    "        ##TF-IDF\n",
    "        r = 0\n",
    "        if word in frec_word:\n",
    "            tf = ( (k+1)*frec_word[word] ) / ( frec_word[word] + k*norm )\n",
    "            idf = math.log( float(cant_reviews+1)/frec[word] )\n",
    "            r = tf * idf\n",
    "#            r = frec_word[word]\n",
    "\n",
    "        if word in frec_pos and word in frec_neg:\n",
    "            Pt = frec_pos[word]\n",
    "            Nt = frec_neg[word]\n",
    "\n",
    "#            Vt += r * math.log(float(Nt)/Pt , 2 )\n",
    "            Vt += r * float(Nt)/Pt\n",
    "\n",
    "        else:\n",
    "            Vt += 0\n",
    "    \"\"\"\n",
    "        pos = 0\n",
    "        if word in frec_pos:\n",
    "            Pt = frec_pos[word]\n",
    "            pos = r * math.log( cant_pos/float(Pt) , 2 )\n",
    "\n",
    "        neg = 0\n",
    "        if word in frec_neg:\n",
    "            Nt = frec_neg[word]\n",
    "            neg = r * math.log( cant_neg/float(Nt) , 2 )\n",
    "\n",
    "        Vt += pos - neg\n",
    "    \"\"\"\n",
    "    return [Vt, review_train[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def delta_tfidf(review_test, review_train):\n",
    "    texto = review_test[2]\n",
    "    frec_word = review_train[3]\n",
    "\n",
    "    r = 0\n",
    "    k = 1.2\n",
    "    # NORMALIZAR\n",
    "    b = 0.75\n",
    "    long_doc = len(texto)\n",
    "    norm = 1 - b + b * (long_doc / promedio_long_docs)\n",
    "\n",
    "    for word in texto:\n",
    "        ## TF-IDF\n",
    "        tf = 0\n",
    "\n",
    "        if word in frec_word:\n",
    "            #BM25\n",
    "            tf = ( (k+1)*frec_word[word] ) / ( frec_word[word] + k*norm )\n",
    "\n",
    "        idf_pos = 0\n",
    "        if word in frec_pos:\n",
    "            Pt = frec_pos[word]\n",
    "            idf_pos = math.log( 1 + (cant_pos+1) / Pt)\n",
    "\n",
    "        idf_neg = 0\n",
    "        if word in frec_neg:\n",
    "            Nt = frec_neg[word]\n",
    "            idf_neg = math.log( 1 + (cant_neg+1) / Nt)\n",
    "\n",
    "        r += tf * ( idf_pos - idf_neg )\n",
    "\n",
    "    return [abs(r), review_train[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TF-IDF\n",
    "import math\n",
    "\n",
    "\n",
    "frecs_por_docs = train_preprocesado.flatMap(frec_por_doc).reduceByKey( lambda x,y: x+y )\n",
    "frecs_por_docs = frecs_por_docs.collect()\n",
    "\n",
    "frec = {}\n",
    "\n",
    "for word in frecs_por_docs:\n",
    "    frec[word[0]] = word[1]\n",
    "\n",
    "#print \" \"\n",
    "#print \"frecs_por_docs: \", frec\n",
    "\n",
    "\n",
    "cant_reviews = train_preprocesado.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long:  10316425\n",
      "promedio:  45.0347481415\n"
     ]
    }
   ],
   "source": [
    "## NORMALIZAR DATOS\n",
    "\n",
    "train_long_docs = train_preprocesado.map( lambda review: (1, len(review[2])) ).reduceByKey( lambda x, y: x+y )\n",
    "long_docs = train_long_docs.collect()\n",
    "long_docs = long_docs[0][1]\n",
    "print \"long: \", long_docs\n",
    "\n",
    "promedio_long_docs = float(long_docs) / cant_reviews\n",
    "print \"promedio: \", promedio_long_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sentimiento(word, word_ant):\n",
    "    sentimiento = 0\n",
    "\n",
    "    if word in palabras_pos or word in palabras_neg:\n",
    "        return 2\n",
    "\n",
    "    return 1\n",
    "\n",
    "\"\"\"\n",
    "    if word in palabras_pos:\n",
    "        if word_ant not in palabras_sentimiento_inverso:\n",
    "            sentimiento += palabras_pos[word]\n",
    "        else:\n",
    "            sentimiento += palabras_pos[word]\n",
    "\n",
    "    if word in palabras_neg:\n",
    "        if word_ant not in palabras_sentimiento_inverso:\n",
    "            sentimiento -= palabras_neg[word]\n",
    "        else:\n",
    "            sentimiento -= palabras_neg[word]\n",
    "\n",
    "    return sentimiento\n",
    "\"\"\"\n",
    "\n",
    "def tfidf(review_test, review_train):\n",
    "    texto = review_test[2]\n",
    "    frec_word = review_train[3]\n",
    "    r = 0\n",
    "\n",
    "    k = 1.2\n",
    "    b = 0.75\n",
    "    long_doc = len(texto)\n",
    "    norm = 1 - b + b * (long_doc / promedio_long_docs)\n",
    "\n",
    "    ## SENTIMIENTO\n",
    "    for i in range( len(texto) ):\n",
    "        word_ant = \"\"\n",
    "        if i>0:\n",
    "            word_ant = texto[i-1]\n",
    "        word = texto[i]\n",
    "#        sent = sentimiento(word, word_ant)\n",
    "\n",
    "        ## TF-IDF\n",
    "        tf = 0\n",
    "        idf = 0\n",
    "\n",
    "        if word in frec_word:\n",
    "            #BM25\n",
    "            tf = ( (k+1)*frec_word[word] ) / ( frec_word[word] + k*norm )\n",
    "#            print \"cant_reviews: \", cant_reviews\n",
    "#            print \"frec[word]: \", frec[word]\n",
    "            idf = math.log( float(cant_reviews+1)/frec[word] )\n",
    "\n",
    "        r += tf * idf\n",
    "#        r += tf * idf * sent\n",
    "\n",
    "    return [r, review_train[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_PRED:  [201541, 3]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [6911, 2]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [461853, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [563294, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [471402, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [139618, 5]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [248946, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [163663, 1]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [140792, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [340744, 1]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [278204, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [165496, 1]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [415793, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [268341, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [371580, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [538393, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [415317, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [524561, 1]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [55501, 3]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [545857, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [64276, 5]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [549022, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [402962, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [514329, 5]\n",
      "PRED:  1.66666666667\n",
      "TEST_PRED:  [549413, 4]\n",
      "PRED:  3.0\n",
      "TEST_PRED:  [419544, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [206761, 5]\n",
      "PRED:  1.0\n",
      "TEST_PRED:  [108099, 5]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [267342, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [321418, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [131474, 1]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [466699, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [134792, 4]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [65195, 4]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [15231, 4]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [206091, 5]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [32605, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [43035, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [323477, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [140464, 3]\n",
      "PRED:  1.66666666667\n",
      "TEST_PRED:  [319518, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [460611, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [309176, 3]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [410665, 5]\n",
      "PRED:  3.0\n",
      "TEST_PRED:  [25508, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [152198, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [352990, 4]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [266721, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [107812, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [499355, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [253273, 3]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [190130, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [172911, 1]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [231001, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [435736, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [385226, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [323953, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [319405, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [271436, 1]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [147683, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [218448, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [469711, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [33160, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [121607, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [166383, 2]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [191079, 4]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [30045, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [208336, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [565008, 5]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [124276, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [260917, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [503095, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [564067, 3]\n",
      "PRED:  4.0\n",
      "TEST_PRED:  [25160, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [173632, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [28611, 3]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [566718, 5]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [56698, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [36389, 4]\n",
      "PRED:  4.66666666667\n",
      "TEST_PRED:  [554634, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [823, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [190174, 4]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [229283, 4]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [130479, 5]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [248282, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [389109, 4]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [71639, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [91215, 3]\n",
      "PRED:  2.66666666667\n",
      "TEST_PRED:  [181065, 4]\n",
      "PRED:  4.33333333333\n",
      "TEST_PRED:  [234106, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [412489, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [419115, 4]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [489362, 1]\n",
      "PRED:  3.66666666667\n",
      "TEST_PRED:  [370772, 3]\n",
      "PRED:  2.33333333333\n",
      "TEST_PRED:  [518729, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [42903, 5]\n",
      "PRED:  3.33333333333\n",
      "TEST_PRED:  [181626, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [104145, 5]\n",
      "PRED:  2.0\n",
      "TEST_PRED:  [66398, 5]\n",
      "PRED:  5.0\n",
      "TEST_PRED:  [244952, 4]\n",
      "PRED:  4.33333333333\n",
      " \n",
      "ERROR:  12.0462073331\n",
      "accuracy:  29.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def knn(texto_estruct, k):\n",
    "\n",
    "#    dist = train_frec.map(lambda vecino: tfidf(texto_estruct, vecino))\n",
    "    dist = train_frec.map(lambda vecino: delta_tfidf(texto_estruct, vecino))\n",
    "\n",
    "#    k_mas_cercanos = dist.takeOrdered(k, key=lambda x: x[2])\n",
    "    ## PARA DIST2\n",
    "    k_mas_cercanos = dist.takeOrdered(k, key=lambda x: -x[0])\n",
    "\n",
    "    return k_mas_cercanos\n",
    "\n",
    "def predecir(k_mas_cercanos):\n",
    "    prediccion_total = 0\n",
    "    for cercano in k_mas_cercanos:\n",
    "        prediccion_total += cercano[1]\n",
    "\n",
    "    return float(prediccion_total) / len(k_mas_cercanos)\n",
    "\n",
    "\n",
    "reviewRDD = sc.textFile(\"reviews_test\")\n",
    "review_dataframe = pycsv.csvToDataFrame(sqlCtx, reviewRDD, parseDate=False)\n",
    "reviews = review_dataframe.rdd\n",
    "\n",
    "reviews_preprocesado = reviews.map(preprocesar)\n",
    "reviews = reviews_preprocesado.collect()\n",
    "\n",
    "cant_ej = 100\n",
    "test = test_preprocesado.take(cant_ej)\n",
    "#for t in test:\n",
    "#    print \"t: \", t\n",
    "\n",
    "## PREDECIR VARIOS\n",
    "error = 0\n",
    "correct = 0\n",
    "for test_pred in test:\n",
    "    print \"TEST_PRED: \", test_pred[0:2]\n",
    "\n",
    "    k_mas_cercanos = knn(test_pred, 3)\n",
    "#    print \"k_mas_cercanos: \", k_mas_cercanos\n",
    "\n",
    "    prediccion = predecir(k_mas_cercanos)\n",
    "\n",
    "    print \"PRED: \", prediccion\n",
    "\n",
    "    if prediccion == test_pred[1]:\n",
    "        correct += 1\n",
    "    error += (prediccion - test_pred[1])**2\n",
    "\n",
    "print \" \"\n",
    "error = sqrt(error)\n",
    "print \"ERROR: \", error\n",
    "\n",
    "print \"accuracy: \", ( float(correct)/cant_ej ) * 100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
